

### command line tool usage:
``` 
$ python3 merge.py info log*.txt
```
### Размышления на тему задачки
* Наверное, стоит переписать модуль в единый класс и разграничить доступ по методам, тогда и юнит тесты будут более удобными для написания, я сначала набросал так как вы его видите, переписать думаю в ближайшее время, но если честно, хотелось бы быстрее зааплаиться к вам, в свободное время (если такое будет) перепишу и скину другую версию
* Основная идея моего решения полностью копирует часть сортировки слиянием (ту которая сливает, собственно :)
    * Бежим по всем файлам, создаем для каждого файла «бегунок»
    * На каждой итерации берем минимально подходящую (сравниваем по дате, не забываем про лог-левел) запись лога, если дошли до конца файла, а записи нет — бегунок убивается
    * Повторяем пока есть «живые» бегунки
* Юниттесты получились достаточно исскуственными — как я писал выше, завернув это все в один объект можно было бы лучше контролировать его стейт, соответственно тестировать поведение объекта в конкретном стейте
* В зависимости от реальных объемов данных, вполне вероятно было бы написать решение «в лоб» и жрать файл целиком в память, мне показалось что от меня ждут другого решения
* Тем не менее, решение в лоб на некоторых конфигурациях (и при условии не шибко больших файлов) будет работать быстрее. Например, у меня на маке 2к маленьких файлов отрабатывали дольше, возможно файловая система немного вешалась от внутрифайловых переходов
* В реальной жизни, я бы скорее всего написал решение исключительно пайпами и юникс утилитами, хотя если в ближайшем будущем были планы добавлять логики и, возможно, писать логи в какую-нибудь кафку и тд — то решение отдельным скриптом выглядит более лучшим, так как его легче поддерживать in the long run
